import nltk
from nltk.corpus import stopwords
import string
import pandas as pd
nltk.download('punkt')
nltk.download('stopwords')

# Sample corpus

data = pd.read_csv(r"C:\Users\panos\OneDrive\Υπολογιστής\M.sc\Newro\Assignment Sgou\amazon_review_full_csv\train.csv", nrows=5750)


data = pd.DataFrame({
    'rating': data.iloc[:, 0] ,     # First column from the CSV file ('rating')
    'comments': data.iloc[:, 2]    # Third column from the CSV file ('comment')
})

corpus = data['comments']
# Function to preprocess text
def preprocess_text(text):
    # Tokenize text into words
    words = nltk.word_tokenize(text)
    
    # Convert words to lowercase
    words = [word.lower() for word in words]
    
    # Remove punctuation
    words = [word for word in words if word not in string.punctuation]
    
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    words = [word for word in words if word not in stop_words]
    
    return words

# Preprocess each sentence in the corpus
preprocessed_corpus = [preprocess_text(sentence) for sentence in corpus]

print(preprocessed_corpus)
